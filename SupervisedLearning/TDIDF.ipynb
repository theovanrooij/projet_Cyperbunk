{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\theov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\theov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\theov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\theov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from interpret.glassbox import LogisticRegression\n",
    "from interpret import show\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../Processing/')\n",
    "\n",
    "from preprocessing import Preprocess_English_Sentence,Preprocess_French_Sentence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Processing/vocab.txt\", \"r\",encoding=\"utf-8\")as f :\n",
    "    vocab = f.read().split(\"\\n\")\n",
    "    vectorizer = CountVectorizer(max_features=6000,vocabulary=vocab,stop_words=\"english\",binary=True,ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyberpunk = pd.read_json(\"../Processing/processed_files/wattpad/cyberpunk-preprocessed.json\")\n",
    "space = pd.read_csv(\"../Processing/processed_files/wattpad/space-encoded.csv\")\n",
    "romance = pd.read_csv(\"../Processing/processed_files/wattpad/romance-encoded.csv\")\n",
    "crime = pd.read_csv(\"../Processing/processed_files/wattpad/crime-encoded.csv\")\n",
    "\n",
    "thriller = pd.read_csv(\"../Processing/processed_files/wattpad/thriller-encoded.csv\")\n",
    "vampire = pd.read_csv(\"../Processing/processed_files/wattpad/vampire-encoded.csv\")\n",
    "fantasy = pd.read_csv(\"../Processing/processed_files/wattpad/fantasy-encoded.csv\")\n",
    "\n",
    "\n",
    "science_fantasy = pd.read_csv(\"../Processing/processed_files/wattpad/science-fantasy-encoded.csv\")\n",
    "steampunk = pd.read_csv(\"../Processing/processed_files/wattpad/steampunk-encoded.csv\")\n",
    "horror = pd.read_csv(\"../Processing/processed_files/wattpad/horror-encoded.csv\")\n",
    "\n",
    "humour = pd.read_csv(\"../Processing/processed_files/wattpad/humour-encoded.csv\")\n",
    "dystopie = pd.read_csv(\"../Processing/processed_files/wattpad/dystopie-encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"neuromancien.txt\", \"r\")\n",
    "content = f.read()\n",
    "process_content = Preprocess_French_Sentence(content)\n",
    "\n",
    "matrix = vectorizer.fit_transform([process_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",binary=True,ngram_range=(1,2),min_df = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform([process_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<885x415 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 160062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit_transform(cyberpunk[\"preprocess_story_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'actually', 'age', 'ago', 'air', 'alive', 'answer', 'area',\n",
       "       'arm', 'ask', 'attention', 'away', 'bad', 'barely', 'bed',\n",
       "       'believe', 'best', 'better', 'big', 'bit', 'black', 'blood',\n",
       "       'blue', 'body', 'book', 'boy', 'brain', 'break', 'breath',\n",
       "       'bright', 'bring', 'broken', 'brought', 'brown', 'building',\n",
       "       'calm', 'came', 'car', 'care', 'case', 'catch', 'caught', 'chair',\n",
       "       'chance', 'change', 'check', 'chest', 'child', 'city', 'clean',\n",
       "       'clear', 'close', 'closed', 'closer', 'clothes', 'cold', 'come',\n",
       "       'coming', 'completely', 'computer', 'continued', 'control',\n",
       "       'corner', 'course', 'cover', 'covered', 'cut', 'dark', 'darkness',\n",
       "       'day', 'dead', 'death', 'decided', 'deep', 'didnt', 'die',\n",
       "       'different', 'direction', 'distance', 'doesnt', 'dont',\n",
       "       'dont know', 'door', 'ear', 'earth', 'edge', 'end', 'entire',\n",
       "       'escape', 'exactly', 'eye', 'face', 'fact', 'fall', 'family',\n",
       "       'far', 'fast', 'father', 'fear', 'feel', 'feeling', 'fell', 'felt',\n",
       "       'fight', 'figure', 'filled', 'finally', 'fine', 'finger', 'floor',\n",
       "       'follow', 'food', 'foot', 'force', 'form', 'forward', 'free',\n",
       "       'friend', 'future', 'game', 'gave', 'getting', 'girl', 'given',\n",
       "       'giving', 'glass', 'god', 'going', 'gone', 'good', 'got', 'great',\n",
       "       'green', 'ground', 'group', 'guard', 'guess', 'gun', 'guy', 'hair',\n",
       "       'half', 'hand', 'happen', 'happy', 'hard', 'head', 'hear', 'heart',\n",
       "       'heavy', 'hell', 'help', 'hey', 'high', 'hit', 'hold', 'holding',\n",
       "       'home', 'hope', 'hour', 'house', 'human', 'hurt', 'id', 'idea',\n",
       "       'ill', 'immediately', 'information', 'inside', 'instead', 'job',\n",
       "       'kept', 'kill', 'kind', 'knee', 'knew', 'know', 'knowing', 'known',\n",
       "       'large', 'late', 'later', 'lead', 'leave', 'leaving', 'left',\n",
       "       'leg', 'let', 'level', 'life', 'light', 'like', 'line', 'lip',\n",
       "       'little', 'live', 'living', 'long', 'longer', 'look', 'look like',\n",
       "       'looking', 'lost', 'lot', 'loud', 'love', 'low', 'machine', 'main',\n",
       "       'make', 'making', 'man', 'matter', 'maybe', 'mean', 'meant',\n",
       "       'meet', 'memory', 'men', 'met', 'metal', 'middle', 'mind',\n",
       "       'minute', 'moment', 'money', 'month', 'morning', 'mother', 'mouth',\n",
       "       'moving', 'na', 'near', 'neck', 'need', 'new', 'nice', 'night',\n",
       "       'noise', 'normal', 'number', 'oh', 'old', 'open', 'order',\n",
       "       'outside', 'pain', 'past', 'pay', 'people', 'perfect', 'person',\n",
       "       'pick', 'picked', 'piece', 'place', 'plan', 'play', 'pocket',\n",
       "       'point', 'possible', 'power', 'pretty', 'probably', 'problem',\n",
       "       'pull', 'question', 'quick', 'quickly', 'quiet', 'quite', 'raised',\n",
       "       'ran', 'reach', 'read', 'ready', 'real', 'really', 'reason', 'red',\n",
       "       'remember', 'rest', 'right', 'room', 'run', 'running', 'safe',\n",
       "       'said', 'sat', 'saw', 'say', 'saying', 'screen', 'seat', 'second',\n",
       "       'seeing', 'seen', 'sense', 'sent', 'set', 'shadow', 'shook',\n",
       "       'short', 'shot', 'shoulder', 'shut', 'sight', 'sign', 'silence',\n",
       "       'silent', 'single', 'sitting', 'situation', 'skin', 'sky', 'sleep',\n",
       "       'slightly', 'slowly', 'small', 'smile', 'soon', 'sorry', 'sort',\n",
       "       'sound', 'space', 'spoke', 'spot', 'stand', 'standing', 'staring',\n",
       "       'start', 'stay', 'step', 'stepped', 'stood', 'stop', 'stopped',\n",
       "       'story', 'straight', 'street', 'strong', 'stuff', 'suddenly',\n",
       "       'sun', 'supposed', 'sure', 'table', 'taken', 'taking', 'talk',\n",
       "       'talking', 'tall', 'tear', 'tell', 'thank', 'thanks', 'thats',\n",
       "       'theyre', 'thing', 'think', 'thinking', 'thought', 'time', 'today',\n",
       "       'told', 'took', 'tried', 'true', 'try', 'trying', 'turn', 'turned',\n",
       "       'turning', 'understand', 'use', 'used', 'view', 'vision', 'voice',\n",
       "       'wait', 'waiting', 'walk', 'walking', 'wall', 'want', 'war',\n",
       "       'wasnt', 'watch', 'watched', 'watching', 'water', 'way', 'weapon',\n",
       "       'wearing', 'week', 'went', 'werent', 'whats', 'white', 'wide',\n",
       "       'window', 'wish', 'woman', 'wont', 'word', 'work', 'worked',\n",
       "       'working', 'world', 'worry', 'wouldnt', 'wrong', 'yeah', 'year',\n",
       "       'yes', 'young'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
